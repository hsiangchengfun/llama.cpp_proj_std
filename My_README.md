## Name : XXX

### Inference Performance

| Throughputs (Tokens/sec) | CPU      | GPU      | Accuracy  |
| --------                 | -------- | -------- | --------  |
| Model1                   | XXXX     | XXXX     | 10/10     |
| Model2                   | XXXX     | XXXX     | 10/10     |
| Model3                   | XXXX     | XXXX     | 10/10     |

### Questions
* What problems you encountered? How you solve it?
* What you observed between CPU / GPU performance ?    
* Will quantization or smaller-parameters model impact model accuracy or inference throughput ? If so , what's the variation?
